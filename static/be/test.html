<!doctype html>
<html lang="en">

<head>
    <style>
        body{
            background-color: black;
            margin: 0px; padding: 0px; overflow: hidden;
        }
        #wait{
            color:white;
            font-family: system-ui;
            font-size: 42px;
            z-index: 3000;
            text-align: center;
            position: absolute;
            width: 100%;
            padding-top: 15%;
        }
        #video {
            position:absolute;
            top: -0;
            left: 0;
            right: 0;
            bottom: 0;
        }
    </style>
    <meta charset="utf-8">
    <title>Be the sun</title>
    <meta name="description"
        content="A once in a life-time occasion to be the sun, making sunsets and sunrises whenever you want">
    <meta name="author" content="Davide Prati">
    <!-- <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh"></script> -->
    <script src="./js/regl.min.js"></script>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>

    <!-- https://github.com/google/mediapipe/blob/master/docs/solutions/face_detection.md -->


<script type="module">
import * as THREE from 'https://threejsfundamentals.org/threejs/resources/threejs/r127/build/three.module.js';

const FACE_UP = 10
const FACE_DOWN = 152
const NOSE_TIP = 2
const VIDEO_WIDTH = 300
const VIDEO_HEIGHT = 225
// const VIDEO_WIDTH = 1400
// const VIDEO_HEIGHT = 1050
const SUN_SIZE_MAX = 1.0
const SUN_SIZE_MIN = 0.2

const videoElement = document.getElementById('video');
const canvasElement = document.getElementById('facecanvas');


const faceMesh = new FaceMesh({
    locateFile: (file) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`;
    }
});

faceMesh.setOptions({
    maxNumFaces: 1,
    minDetectionConfidence: 0.5,
    minTrackingConfidence: 0.5
});

/*
function initThreeApp(canvas, w, h) {
    const renderer = new THREE.WebGLRenderer({
        canvas,
        alpha: true,
        antialias: true,
    })

    const fov = 75
    const near = 0.01
    const far = 1000
    const camera = new THREE.PerspectiveCamera(fov, 1280/720, near, far)
    camera.position.z = 2;

    const scene = new THREE.Scene()

    function resize() {
        const width = w || window.innerWidth
        const height = h || window.innerHeight

        renderer.setSize(width, height)
        renderer.setPixelRatio(window.pixelRatio)

        if (camera.isPerspectiveCamera) {
            camera.aspect = width / height
        }
        camera.updateProjectionMatrix()
    }

    function render() {
        renderer.render(scene, camera)
    }

    // initial resize and render
    resize()
    render()


    // add a light
    const color = 0xFFFFFF
    const intensity = 1
    const light = new THREE.DirectionalLight(color, intensity)
    light.position.set(-1, 2, 4)
    scene.add(light)

    // add a box
    const boxWidth = 1
    const boxHeight = 1
    const boxDepth = 1
    const geometry = new THREE.BoxGeometry(boxWidth, boxHeight, boxDepth)
    const material = new THREE.MeshPhongMaterial({
        color: 0x44aa88,
        transparent: true,
        opacity: 0.8
    })
    const cube = new THREE.Mesh(geometry, material)
    scene.add(cube)

    return {
        renderer,
        camera,
        scene,
        resize,
        render,
        cube
    }
}


initVideo(videoElement, 320, 180)
const threeApp = initThreeApp(canvasElement,1280,720)

const onResults = function(res){
    console.log("calles")
  const landmarks = res.multiFaceLandmarks
  if(!landmarks) return;
  const {x, y, z} = landmarks[0][1];
  // landmarks[0][1] == nose position(face center point)
  // use landmarks xy value to calculate the screen xy
  let vec = new THREE.Vector3();
  let pos = new THREE.Vector3();
  vec.set(
    x * 2 - 1,
    -y * 2 + 1,
    0.5);
  vec.unproject(threeApp.camera);
  vec.sub(threeApp.camera.position).normalize();
  let distance = -threeApp.camera.position.z / vec.z;
  pos.copy(threeApp.camera.position).add(vec.multiplyScalar(distance));
  threeApp.cube.position.x = pos.x;
  threeApp.cube.position.y = pos.y;

}

faceMesh.onResults(onResults);

const run = async function(){
  threeApp.render()
  await faceMesh.send({image: videoElement})
  requestAnimationFrame(run)
}

*/












let headPosition = [200.0, 200.0]
let sunSize = 0.6



initVideo(videoElement, 320, 180)
const regl = createREGL({canvas: canvasElement})
const drawTriangle = regl({
        frag: `
            precision mediump float;
            uniform float uSunSize;
            uniform vec2 iResolution;
            uniform vec2 uHead;

            float circleSmooth(in vec2 st, in vec2 pos, in float begin, in float end) {
                float pct = 0.0;
                pct = 1. - smoothstep(begin, end, distance(st, pos));
                return pct;
            }

            float rectangleGradientBottom(in vec2 st, in vec2 origin, in vec2 dimensions, float smoothness) {
                vec2 center = step(origin, st); // it is actually the bottom left cornter
                float pct = center.x * center.y;
                vec2 full = step(1.0 - origin - dimensions, 1.0 - st);
                float height = origin.y+dimensions.y;
                pct *= full.x * full.y;
                pct *= smoothstep(height, origin.y+smoothness,st.y);
                return pct;
            }

            //  Function from IÃ±igo Quiles
            //  www.iquilezles.org/www/articles/functions/functions.htm
            float parabola( float x, float k ){
                return pow( 4.0*x*(1.0-x), k );
            }

            void main() {
                vec2 uv = gl_FragCoord.xy / iResolution.xy;
                vec2 headNorm = uHead/iResolution;
                // use parabola function to get the y coordinate
                //vec2 m = vec2(headNorm.x, parabola(headNorm.x, 1.2));
                vec2 m = vec2(headNorm.x, headNorm.y);
                vec3 color = vec3(0.1, 0.4, 0.9);
                color += vec3(0.9-m.y,0.6-uv.y, -(1.0-m.y));
                uv.x *= iResolution.x / iResolution.y;
                m.x *= iResolution.x / iResolution.y;
                vec2 recPos = vec2(0.0, 0.0);

                // kind of sun, with a lot of imagination
                color.rg += circleSmooth(uv, vec2(m), 0.05, 0.15 + uSunSize);
                float turnOffSky = smoothstep(0.25, 0.27,m.y);
                color*= turnOffSky;

                // earth
                vec3 earth = vec3(vec2(rectangleGradientBottom(uv, recPos, vec2(40.0, 0.3), 0.16)), 0.0);
                earth.r += 1.0 -m.y;
                color += earth;
                float turnOffEarth = smoothstep(0.09, 0.25,m.y);
                color*= turnOffEarth;

                gl_FragColor = vec4(color, 1.0);
            }`,

        vert: `
            precision mediump float;
            attribute vec3 position;

            void main() {
                gl_Position = vec4(position, 1);
            }`,

        attributes: {
            position: regl.buffer([
                [[-1, -1, 0], [-1, 1, 0], [1, 1, 0]],
                [[1, 1, 0], [1, -1, 0], [-1, -1, 0]]
            ])
        },

        uniforms: {
            iResolution: regl.prop('resolution'),
            uSunSize: regl.prop('sunSize'),
            uHead: regl.prop('headPosition')
        },
        count: 6
    })    

function map_range(value, low1, high1, low2, high2) {
    let mapped = low2 + (high2 - low2) * (value - low1) / (high1 - low1)
    return Math.min(Math.max(mapped, low2), high2)
}

const onResults = function(res){
    const landmarks = res.multiFaceLandmarks
    if(!landmarks || !landmarks[0]) return;
    const {x, y, z} = landmarks[0][1];
    //console.log(res)
    let x_nose = map_range(x, 0 , 1, 0, canvasElement.width);
    let y_nose = map_range(y, 1, 0, 0, canvasElement.height);
    headPosition = [x_nose, y_nose]
    sunSize = map_range(z, -0.03, -0.12, SUN_SIZE_MIN, SUN_SIZE_MIN)
    console.log(x_nose, y_nose);
    //let z = map_range(headHeight, 0, video.videoHeight, 0, 1.0) * 0.8;
  // landmarks[0][1] == nose position(face center point)
  // use landmarks xy value to calculate the screen xy


}

faceMesh.onResults(onResults);

const run = async function(){
    regl.frame(function (context) {
        drawTriangle({
            resolution: [context.drawingBufferWidth, context.drawingBufferHeight],
            sunSize: sunSize,
            headPosition: headPosition
        })
    })
    await faceMesh.send({image: videoElement})
    requestAnimationFrame(run)
}


function removeWaitingMessage(){
    let msg = document.getElementById('wait')
    msg.remove()
}

function initVideo(video, w, h){
  if ( navigator.mediaDevices && navigator.mediaDevices.getUserMedia ) {
    const constraints = { video: { width: w, height: h, facingMode: 'user' } };
    navigator.mediaDevices.getUserMedia( constraints ).then( function ( stream ) {
        // apply the stream to the video element used in the texture
        video.srcObject = stream;
        video.play();
        removeWaitingMessage()
        run();
    } ).catch( function ( error ) {
        console.error( 'Unable to access the camera/webcam.', error );
    } );
    } else {
        removeWaitingMessage()
        console.error( 'MediaDevices interface not available.' );
    }
}


</script>


</head>

<body>
    <div id="wait">Wait for camera to be detected, otherwise use the mouse as input</div>
    <!-- <video autoplay muted 
        playsinline hidden id="video"
        style=" top:0px; left: 500px"
        width="300" height="225"
        >
	</video> -->

    <video id="video"></video>
    <canvas id="facecanvas"></canvas>
</body>
</html>